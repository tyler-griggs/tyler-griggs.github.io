*MoE-Lightning*: High-Throughput MoE Inference on Memory-constrained GPUs\
Shiyi Cao, Shu Liu, **Tyler Griggs**, Peter Schafhalter, Xiaoxuan Liu, Ying Sheng, Joseph E Gonzalez, Matei Zaharia, Ion Stoica\
<span style="font-style:italic">ASPLOS 2025</span> [<a style="text-decoration:none" href="https://arxiv.org/abs/2411.11217" target="_blank">Paper</a>]

*SkyServe*: Serving AI Models across Regions and Clouds with Spot Instances\
Ziming Mao, Tian Xia, Zhanghao Wu, Wei-Lin Chiang, **Tyler Griggs**, Romil Bhardwaj, Zongheng Yang, Scott Shenker, Ion Stoica\
<span style="font-style:italic">arXiv preprint</span> [<a style="text-decoration:none" href="https://arxiv.org/pdf/2411.01438" target="_blank">Paper</a>]

*MÃ©lange*: Cost Efficient Large Language Model Serving by Exploiting GPU Heterogeneity\
**Tyler Griggs**, Xiaoxuan Liu, Jiaxiang Yu, Doyoung Kim, Wei-Lin Chiang, Alvin Cheung, Ion Stoica\
<span style="font-style:italic">arXiv preprint</span> [<a style="text-decoration:none" href="https://arxiv.org/abs/2404.14527" target="_blank">Paper</a>] [<a style="text-decoration:none" href="https://github.com/tyler-griggs/melange-release" target="_blank">Code</a>]
