<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tyler Griggs</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
</head>
<body>
    <div class="profile">
        <div class="profile-image-container">
            <img src="images/tyler_profile.png" alt="Tyler Griggs">
            <div class="social-icons">
                <a href="https://www.linkedin.com/in/tyler-griggs/" target="_blank" aria-label="LinkedIn"><i class="fab fa-linkedin"></i></a>
                <a href="https://scholar.google.com/citations?user=OlrVINUAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"><i class="fas fa-graduation-cap"></i></a>
                <a href="https://x.com/tyler_griggs_" target="_blank" aria-label="X (Twitter)"><i class="fab fa-x-twitter"></i></a>
                <a href="https://github.com/tyler-griggs" target="_blank" aria-label="GitHub"><i class="fab fa-github"></i></a>
            </div>
            <div class="email">Email: tgriggs AT berkeley.edu</div>
        </div>
        <div>
            <h1>Tyler Griggs</h1>
            <p>I am a third year PhD student in Computer Science in the UC Berkeley <a href="https://sky.cs.berkeley.edu/">Sky Computing Lab</a> advised by <a href="http://people.eecs.berkeley.edu/~istoica/">Ion Stoica</a> and <a href="https://people.eecs.berkeley.edu/~matei/">Matei Zaharia</a>, and supported by the Amazon AI PhD Fellowship. Previously, I worked in Network Infrastructure at Google Cloud. Before that, I graduated from Harvard with a BA in Computer Science advised by <a href="https://mickens.seas.harvard.edu/">James Mickens</a>.</p>
            <p>My research interests are in designing and building flexible and efficient systems for model training and inference, and leveraging these systems to develop models useful in real-world tasks. My current research focuses on systems for post-training, especially reinforcement learning. Along with several wonderful collaborators, I am a co-lead of the <a href="https://novasky-ai.github.io/posts/about-us/">NovaSky</a> team and building <a href="https://github.com/NovaSky-AI/SkyRL">SkyRL</a>. Our work has been featured in <a href="https://www.nytimes.com/2025/01/23/technology/deepseek-china-ai-chips.html">The New York Times</a>, <a href="https://www.wsj.com/tech/ai/why-distillation-has-become-the-scariest-wordfor-ai-companies-aa146ae3">The Wall Street Journal</a>, and <a href="https://www.theinformation.com/articles/why-its-cheap-and-easy-to-mimic-openais-reasoning-model">The Information</a>.</p>
        </div>
    </div>

    <h2>Current Projects</h2>

    <div class="project">
        <a href="https://github.com/NovaSky-AI/SkyRL" target="_blank"><img src="images/skyrl_diagram.png" alt="SkyRL"></a>
        <div class="project-content">
            <strong>SkyRL: A Modular Full-stack RL Library for LLMs</strong> <a href="https://github.com/NovaSky-AI/SkyRL" target="_blank"><img src="https://img.shields.io/github/stars/NovaSky-AI/SkyRL?style=social" alt="GitHub stars" class="github-stars"></a><br>
            SkyRL is a modular, performant RL framework built for multi-turn agentic training, using a simple and flexible design that allows both high-performance execution and adaptation to a wide variety of training scenarios.<br>
            <span class="highlight-text">Train your agent now with <a href="https://github.com/NovaSky-AI/SkyRL">SkyRL</a>, and don't hesitate to reach out!</span><br>
            [<a href="https://github.com/NovaSky-AI/SkyRL">GitHub</a>]
            [<a href="https://novasky-ai.notion.site/skyrl-v01">Blog</a>]
        </div>
    </div>

    <div class="project">
        <a href="https://github.com/NovaSky-AI/SkyThought" target="_blank"><img src="images/novasky.jpg" alt="SkyThought"></a>
        <div class="project-content">
            <strong>SkyThought: A repository to reproduce NovaSky's research</strong> <a href="https://github.com/NovaSky-AI/SkyThought" target="_blank"><img src="https://img.shields.io/github/stars/NovaSky-AI/SkyThought?style=social" alt="GitHub stars" class="github-stars"></a><br>
            The SkyThought repository holds all code needed to reproduce all prior work of the NovaSky team, such as efficient reasoning, reinforcement learning, test-time scaling, and more. See all our work on <a href="https://novasky-ai.github.io/category/One/1/">our website.</a><br>
            [<a href="https://github.com/NovaSky-AI/SkyThought">GitHub</a>]
        </div>
    </div>

    <h2>Prior Projects</h2>

    <div class="project">
        <img src="images/nonthinking.png" alt="Reasoning models can be effective without thinking">
        <div class="project-content">
            <strong>Reasoning models can be effective without thinking</strong><br>
            Wenjie Ma, Jingxuan He, Charlie Snell, <strong>Tyler Griggs</strong>, Sewon Min, Matei Zaharia<br>
            <span class="italic">arXiv preprint</span> 
            [<a href="https://arxiv.org/abs/2504.09858">Paper</a>]
        </div>
    </div>

    <div class="project">
        <img src="images/structure-not-content.png" alt="Structure not Content">
        <div class="project-content">
            <strong>LLMs Can Easily Learn to Reason from Demonstrations</strong>: Structure, not content, is what matters!<br>
            Dacheng Li*, Shiyi Cao*, <strong>Tyler Griggs*</strong>, Shu Liu*, Xiangxi Mo, Eric Tang, Sumanth Hegde, Kourosh Hakhamaneshi, Shishir G Patil, Matei Zaharia, Joseph E Gonzalez, Ion Stoica<br>
            <span class="italic">arXiv preprint</span> 
            [<a href="https://arxiv.org/abs/2502.07374">Paper</a>]
        </div>
    </div>

    <div class="project">
        <img src="images/moe-lightning-thumbnail.png" alt="MoE-Lightning">
        <div class="project-content">
            <strong>MoE-Lightning</strong>: High-Throughput MoE Inference on Memory-constrained GPUs<br>
            Shiyi Cao, Shu Liu, <strong>Tyler Griggs</strong>, Peter Schafhalter, Xiaoxuan Liu, Ying Sheng, Joseph E Gonzalez, Matei Zaharia, Ion Stoica<br>
            <span class="italic">ASPLOS 2025</span> 
            [<a href="https://arxiv.org/abs/2411.11217">Paper</a>]
        </div>
    </div>

    <div class="project">
        <img src="images/sky-serve-thumbnail.png" alt="SkyServe">
        <div class="project-content">
            <strong>SkyServe</strong>: Serving AI Models across Regions and Clouds with Spot Instances<br>
            Ziming Mao, Tian Xia, Zhanghao Wu, Wei-Lin Chiang, <strong>Tyler Griggs</strong>, Romil Bhardwaj, Zongheng Yang, Scott Shenker, Ion Stoica<br>
            <span class="italic">EuroSys 2025</span> 
            [<a href="https://arxiv.org/pdf/2411.01438">Paper</a>]
            [<a href="https://github.com/skypilot-org/skypilot">Code</a>]
        </div>
    </div>

    <div class="project">
        <img src="images/melange-thumbnail.png" alt="Mélange">
        <div class="project-content">
            <strong>Mélange</strong>: Cost Efficient Large Language Model Serving by Exploiting GPU Heterogeneity<br>
            <strong>Tyler Griggs</strong>, Xiaoxuan Liu, Jiaxiang Yu, Doyoung Kim, Wei-Lin Chiang, Alvin Cheung, Ion Stoica<br>
            <span class="italic">arXiv preprint</span> 
            [<a href="https://arxiv.org/abs/2404.14527">Paper</a>]
            [<a href="https://github.com/tyler-griggs/melange-release">Code</a>]
        </div>
    </div>
</body>
</html> 
